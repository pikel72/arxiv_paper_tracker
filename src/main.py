#!/usr/bin/env python3
# ArXivè®ºæ–‡è¿½è¸ªä¸åˆ†æå™¨

import os
import arxiv

import datetime
from pathlib import Path
import openai
import time
import logging
import sys
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from dotenv import load_dotenv
from jinja2 import Template

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                   handlers=[logging.StreamHandler(sys.stdout)])
logger = logging.getLogger(__name__)

# é…ç½®
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
SMTP_SERVER = os.getenv("SMTP_SERVER")
SMTP_PORT = int(os.getenv("SMTP_PORT", "587"))
SMTP_USERNAME = os.getenv("SMTP_USERNAME")
SMTP_PASSWORD = os.getenv("SMTP_PASSWORD")
EMAIL_FROM = os.getenv("EMAIL_FROM")
# æ”¯æŒå¤šä¸ªæ”¶ä»¶äººé‚®ç®±ï¼Œç”¨é€—å·åˆ†éš”
EMAIL_TO = [email.strip() for email in os.getenv("EMAIL_TO", "").split(",") if email.strip()]

PAPERS_DIR = Path("./papers")
RESULTS_DIR = Path("./results")

# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
CATEGORIES = [cat.strip() for cat in os.getenv("ARXIV_CATEGORIES", "math.AP").split(",") if cat.strip()]
MAX_PAPERS = int(os.getenv("MAX_PAPERS", "50"))
SEARCH_DAYS = int(os.getenv("SEARCH_DAYS", "5"))

# ä¸»é¢˜è¿‡æ»¤åˆ—è¡¨ä»ç¯å¢ƒå˜é‡è¯»å–
default_priority_topics = [
    "æµä½“åŠ›å­¦ä¸­åå¾®åˆ†æ–¹ç¨‹çš„æ•°å­¦ç†è®º",
    "Navier-Stokesæ–¹ç¨‹",
    "Euleræ–¹ç¨‹", 
    "Prandtlæ–¹ç¨‹",
    "æ¹æµ",
    "æ¶¡åº¦"
]

default_secondary_topics = [
    "è‰²æ•£åå¾®åˆ†æ–¹ç¨‹çš„æ•°å­¦ç†è®º",
    "åŒæ›²åå¾®åˆ†æ–¹ç¨‹çš„æ•°å­¦ç†è®º", 
    "è°ƒå’Œåˆ†æ",
    "æå¤§ç®—å­",
    "æ¤­åœ†åå¾®åˆ†æ–¹ç¨‹",
    "æŠ›ç‰©åå¾®åˆ†æ–¹ç¨‹"
]

# ä»ç¯å¢ƒå˜é‡è¯»å–ä¸»é¢˜åˆ—è¡¨ï¼Œä½¿ç”¨ | åˆ†éš”
PRIORITY_TOPICS = os.getenv("PRIORITY_TOPICS", "|".join(default_priority_topics)).split("|")
SECONDARY_TOPICS = os.getenv("SECONDARY_TOPICS", "|".join(default_secondary_topics)).split("|")

# APIè°ƒç”¨å»¶æ—¶é…ç½®
PRIORITY_ANALYSIS_DELAY = int(os.getenv("PRIORITY_ANALYSIS_DELAY", "3"))  # é‡ç‚¹è®ºæ–‡åˆ†æå»¶æ—¶ï¼ˆç§’ï¼‰
SECONDARY_ANALYSIS_DELAY = int(os.getenv("SECONDARY_ANALYSIS_DELAY", "2"))  # æ‘˜è¦ç¿»è¯‘å»¶æ—¶ï¼ˆç§’ï¼‰

# é‚®ä»¶é…ç½®
EMAIL_SUBJECT_PREFIX = os.getenv("EMAIL_SUBJECT_PREFIX", "ArXivè®ºæ–‡åˆ†ææŠ¥å‘Š")


def check_topic_relevance(paper):
    """ä½¿ç”¨AIåˆ¤æ–­è®ºæ–‡æ˜¯å¦ç¬¦åˆæŒ‡å®šä¸»é¢˜ï¼Œå¹¶è¿”å›ä¼˜å…ˆçº§"""
    try:
        # ä»Authorå¯¹è±¡ä¸­æå–ä½œè€…å
        author_names = [author.name for author in paper.authors]
        
        # è·å–è®ºæ–‡æ‘˜è¦
        abstract = paper.summary if hasattr(paper, 'summary') else "æ— æ‘˜è¦"
        
        prompt = f"""
        è®ºæ–‡æ ‡é¢˜: {paper.title}
        ä½œè€…: {', '.join(author_names)}
        æ‘˜è¦: {abstract}
        ç±»åˆ«: {', '.join(paper.categories)}
        
        æˆ‘å…³æ³¨ä»¥ä¸‹ç ”ç©¶ä¸»é¢˜ï¼š
        
        é‡ç‚¹å…³æ³¨é¢†åŸŸï¼ˆä¼˜å…ˆçº§1ï¼‰ï¼š
        {chr(10).join([f"- {topic}" for topic in PRIORITY_TOPICS])}
        
        äº†è§£é¢†åŸŸï¼ˆä¼˜å…ˆçº§2ï¼‰ï¼š
        {chr(10).join([f"- {topic}" for topic in SECONDARY_TOPICS])}
        
        è¯·åˆ¤æ–­è¿™ç¯‡è®ºæ–‡æ˜¯å¦ä¸ä¸Šè¿°ä¸»é¢˜ç›¸å…³ï¼Œå¹¶æŒ‡å®šä¼˜å…ˆçº§ã€‚
        
        è¯·åªå›ç­”ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€ï¼š
        ä¼˜å…ˆçº§1 - ç®€è¿°åŸå› ï¼ˆä¸è¶…è¿‡20å­—ï¼‰
        ä¼˜å…ˆçº§2 - ç®€è¿°åŸå› ï¼ˆä¸è¶…è¿‡20å­—ï¼‰
        ä¸ç›¸å…³
        
        æ ¼å¼ç¤ºä¾‹ï¼š
        ä¼˜å…ˆçº§1 - ç ”ç©¶äº†Navier-Stokesæ–¹ç¨‹çš„å­˜åœ¨æ€§
        ä¼˜å…ˆçº§2 - æ¶‰åŠæ¤­åœ†æ–¹ç¨‹çš„æ­£åˆ™æ€§ç†è®º
        ä¸ç›¸å…³
        """
        
        logger.info(f"æ­£åœ¨æ£€æŸ¥ä¸»é¢˜ç›¸å…³æ€§: {paper.title}")
        response = openai.ChatCompletion.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†ç±»ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„æ ¼å¼å›ç­”ã€‚"},
                {"role": "user", "content": prompt},
            ]
        )
        
        result = response.choices[0].message.content.strip()
        logger.info(f"ä¸»é¢˜ç›¸å…³æ€§æ£€æŸ¥ç»“æœ: {result}")
        
        # åˆ¤æ–­ä¼˜å…ˆçº§
        if result.startswith("ä¼˜å…ˆçº§1"):
            reason = result.replace("ä¼˜å…ˆçº§1", "").strip(" -")
            logger.info(f"è®ºæ–‡ç¬¦åˆé‡ç‚¹å…³æ³¨ä¸»é¢˜: {paper.title} - {reason}")
            return 1, reason
        elif result.startswith("ä¼˜å…ˆçº§2"):
            reason = result.replace("ä¼˜å…ˆçº§2", "").strip(" -")
            logger.info(f"è®ºæ–‡ç¬¦åˆäº†è§£ä¸»é¢˜: {paper.title} - {reason}")
            return 2, reason
        else:
            logger.info(f"è®ºæ–‡ä¸ç¬¦åˆä¸»é¢˜è¦æ±‚ï¼Œè·³è¿‡: {paper.title}")
            return 0, "ä¸ç¬¦åˆä¸»é¢˜è¦æ±‚"
            
    except Exception as e:
        logger.error(f"æ£€æŸ¥ä¸»é¢˜ç›¸å…³æ€§å¤±è´¥ {paper.title}: {str(e)}")
        # å‡ºé”™æ—¶é»˜è®¤ä¸ºä¼˜å…ˆçº§2ï¼Œé¿å…é—æ¼
        return 2, f"æ£€æŸ¥å‡ºé”™ï¼Œé»˜è®¤å¤„ç†: {str(e)}"

def translate_abstract_with_deepseek(paper):
    """ä½¿ç”¨DeepSeek APIç¿»è¯‘è®ºæ–‡æ‘˜è¦"""
    try:
        # ä»Authorå¯¹è±¡ä¸­æå–ä½œè€…å
        author_names = [author.name for author in paper.authors]
        
        prompt = f"""
        è¯·å°†ä»¥ä¸‹è‹±æ–‡æ‘˜è¦ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒå­¦æœ¯æ€§å’Œå‡†ç¡®æ€§ï¼š
        
        è®ºæ–‡æ ‡é¢˜: {paper.title}
        æ‘˜è¦: {paper.summary}
        
        è¯·æä¾›ï¼š
        1. æ ‡é¢˜çš„ä¸­æ–‡ç¿»è¯‘
        2. æ‘˜è¦çš„ä¸­æ–‡ç¿»è¯‘ï¼ˆä¿æŒåŸæ–‡çš„å­¦æœ¯è¡¨è¾¾é£æ ¼ï¼‰
        
        æ ¼å¼ï¼š
        **ä¸­æ–‡æ ‡é¢˜**: [ç¿»è¯‘åçš„æ ‡é¢˜]
        
        **æ‘˜è¦ç¿»è¯‘**: [ç¿»è¯‘åçš„æ‘˜è¦]
        """
        
        logger.info(f"æ­£åœ¨ç¿»è¯‘æ‘˜è¦: {paper.title}")
        response = openai.ChatCompletion.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯ç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿æ•°å­¦å’Œç‰©ç†é¢†åŸŸçš„ç¿»è¯‘ã€‚"},
                {"role": "user", "content": prompt},
            ]
        )
        
        translation = response.choices[0].message.content
        logger.info(f"æ‘˜è¦ç¿»è¯‘å®Œæˆ: {paper.title}")
        return translation
    except Exception as e:
        logger.error(f"ç¿»è¯‘æ‘˜è¦å¤±è´¥ {paper.title}: {str(e)}")
        return f"**ç¿»è¯‘å‡ºé”™**: {str(e)}"

# é…ç½®OpenAI APIç”¨äºDeepSeek
openai.api_key = DEEPSEEK_API_KEY
openai.api_base = "https://api.deepseek.com/v1"

# å¦‚æœä¸å­˜åœ¨è®ºæ–‡ç›®å½•åˆ™åˆ›å»º
PAPERS_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)  # åˆ›å»ºç»“æœç›®å½•
logger.info(f"è®ºæ–‡å°†ä¿å­˜åœ¨: {PAPERS_DIR.absolute()}")
logger.info(f"åˆ†æç»“æœå°†å†™å…¥: {RESULTS_DIR.absolute()}")

def get_recent_papers(categories, max_results=MAX_PAPERS):
    """è·å–æœ€è¿‘å‡ å¤©å†…å‘å¸ƒçš„æŒ‡å®šç±»åˆ«çš„è®ºæ–‡"""
    # ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„å¤©æ•°
    today = datetime.datetime.now()
    days_ago = today - datetime.timedelta(days=SEARCH_DAYS)
    
    # æ ¼å¼åŒ–ArXivæŸ¥è¯¢çš„æ—¥æœŸ
    start_date = days_ago.strftime('%Y%m%d')
    end_date = today.strftime('%Y%m%d')
    
    # åˆ›å»ºæŸ¥è¯¢å­—ç¬¦ä¸²
    category_query = " OR ".join([f"cat:{cat}" for cat in categories])
    date_range = f"submittedDate:[{start_date}000000 TO {end_date}235959]"
    query = f"({category_query}) AND {date_range}"
    
    logger.info(f"æ­£åœ¨æœç´¢è®ºæ–‡ï¼ŒæŸ¥è¯¢æ¡ä»¶: {query}")
    logger.info(f"æœç´¢èŒƒå›´: æœ€è¿‘{SEARCH_DAYS}å¤©ï¼Œç±»åˆ«: {', '.join(categories)}ï¼Œæœ€å¤§æ•°é‡: {max_results}")
    
    # æœç´¢ArXiv
    search = arxiv.Search(
        query=query,
        max_results=max_results,
        sort_by=arxiv.SortCriterion.SubmittedDate,
        sort_order=arxiv.SortOrder.Descending
    )
    
    results = list(search.results())
    logger.info(f"æ‰¾åˆ°{len(results)}ç¯‡ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡")
    return results

def download_paper(paper, output_dir):
    """å°†è®ºæ–‡PDFä¸‹è½½åˆ°æŒ‡å®šç›®å½•"""
    pdf_path = output_dir / f"{paper.get_short_id().replace('/', '_')}.pdf"
    
    # å¦‚æœå·²ä¸‹è½½åˆ™è·³è¿‡
    if pdf_path.exists():
        logger.info(f"è®ºæ–‡å·²ä¸‹è½½: {pdf_path}")
        return pdf_path
    
    try:
        logger.info(f"æ­£åœ¨ä¸‹è½½: {paper.title}")
        paper.download_pdf(filename=str(pdf_path))
        logger.info(f"å·²ä¸‹è½½åˆ° {pdf_path}")
        return pdf_path
    except Exception as e:
        logger.error(f"ä¸‹è½½è®ºæ–‡å¤±è´¥ {paper.title}: {str(e)}")
        return None

def analyze_paper_with_deepseek(pdf_path, paper):
    """ä½¿ç”¨DeepSeek APIåˆ†æè®ºæ–‡ï¼ˆä½¿ç”¨OpenAI 0.28.0å…¼å®¹æ ¼å¼ï¼‰"""
    try:
        # ä»Authorå¯¹è±¡ä¸­æå–ä½œè€…å
        author_names = [author.name for author in paper.authors]
        
        prompt = f"""
        è®ºæ–‡æ ‡é¢˜: {paper.title}
        ä½œè€…: {', '.join(author_names)}
        ç±»åˆ«: {', '.join(paper.categories)}
        å‘å¸ƒæ—¶é—´: {paper.published}
        
        è¯·åˆ†æè¿™ç¯‡ç ”ç©¶è®ºæ–‡å¹¶æä¾›ï¼š
        1. ç ”ç©¶å¯¹è±¡å’ŒèƒŒæ™¯: ç»™å‡ºè®ºæ–‡æè¿°çš„æ–¹ç¨‹æˆ–ç³»ç»Ÿ, å¦‚æœåœ¨Introductionçš„éƒ¨åˆ†ç»™å‡ºäº†æ–¹ç¨‹ç»„çš„æ•°å­¦å…¬å¼, è¯·ä¸€å¹¶ç»™å‡º (ç”¨è¡Œé—´å…¬å¼è¡¨ç¤º); å¦‚æœæ–‡ç« ç ”ç©¶çš„æ˜¯æŸä¸€ç§ç°è±¡çš„éªŒè¯, è¯·æè¿°ç°è±¡.
        2. ä¸»è¦å®šç†æˆ–ä¸»è¦ç»“æœ: ç»™å‡ºæ–‡ç« è¯æ˜çš„ä¸»è¦å®šç†.
        3. ç ”ç©¶æ–¹æ³•, å…·ä½“é‡‡ç”¨çš„æŠ€æœ¯, å·¥å…·
        4. ä¸ä¹‹å‰å·¥ä½œçš„æ¯”è¾ƒ: æ–‡ç« æ˜¯å¦å£°ç§°åšå‡ºäº†ä»€ä¹ˆçªç ´æˆ–æ”¹è¿›? å¦‚æœæœ‰ï¼Œè¯·æè¿°.
        
        è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶ä»¥Markdownæ ¼å¼ (åŒ…å«æ•°å­¦å…¬å¼), åˆ†è‡ªç„¶æ®µæ ¼å¼è¾“å‡ºã€‚
        """
        
        logger.info(f"æ­£åœ¨åˆ†æè®ºæ–‡: {paper.title}")
        response = openai.ChatCompletion.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“é—¨æ€»ç»“å’Œåˆ†æå­¦æœ¯è®ºæ–‡çš„ç ”ç©¶åŠ©æ‰‹ã€‚è¯·ä½¿ç”¨ä¸­æ–‡å›å¤ã€‚"},
                {"role": "user", "content": prompt},
            ]
        )
        
        analysis = response.choices[0].message.content
        logger.info(f"è®ºæ–‡åˆ†æå®Œæˆ: {paper.title}")
        return analysis
    except Exception as e:
        logger.error(f"åˆ†æè®ºæ–‡å¤±è´¥ {paper.title}: {str(e)}")
        return f"**è®ºæ–‡åˆ†æå‡ºé”™**: {str(e)}"

def write_to_conclusion(priority_analyses, secondary_analyses):
    """å°†åˆ†æç»“æœå†™å…¥å¸¦æ—¶é—´æˆ³çš„.mdæ–‡ä»¶"""
    today = datetime.datetime.now()
    date_str = today.strftime('%Y-%m-%d')
    time_str = today.strftime('%H-%M-%S')
    
    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
    filename = f"arxiv_analysis_{date_str}_{time_str}.md"
    conclusion_file = RESULTS_DIR / filename
    
    # å†™å…¥åˆ†æç»“æœåˆ°æ–°æ–‡ä»¶
    with open(conclusion_file, 'w', encoding='utf-8') as f:
        f.write(f"# ArXivè®ºæ–‡åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {today.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
        f.write(f"**æœç´¢ç±»åˆ«**: {', '.join(CATEGORIES)}\n")
        f.write(f"**é‡ç‚¹å…³æ³¨è®ºæ–‡æ•°é‡**: {len(priority_analyses)}\n")
        f.write(f"**äº†è§£é¢†åŸŸè®ºæ–‡æ•°é‡**: {len(secondary_analyses)}\n\n")
        f.write("---\n\n")
        
        # å†™å…¥é‡ç‚¹å…³æ³¨çš„è®ºæ–‡ï¼ˆå®Œæ•´åˆ†æï¼‰
        if priority_analyses:
            f.write("# é‡ç‚¹å…³æ³¨è®ºæ–‡ï¼ˆå®Œæ•´åˆ†æï¼‰\n\n")
            for i, (paper, analysis) in enumerate(priority_analyses, 1):
                author_names = [author.name for author in paper.authors]
                
                f.write(f"## {i}. {paper.title}\n\n")
                f.write(f"**ä½œè€…**: {', '.join(author_names)}\n\n")
                f.write(f"**ç±»åˆ«**: {', '.join(paper.categories)}\n\n")
                f.write(f"**å‘å¸ƒæ—¥æœŸ**: {paper.published.strftime('%Y-%m-%d')}\n\n")
                f.write(f"**ArXiv ID**: {paper.get_short_id()}\n\n")
                f.write(f"**é“¾æ¥**: {paper.entry_id}\n\n")
                f.write(f"### è¯¦ç»†åˆ†æ\n\n{analysis}\n\n")
                f.write("---\n\n")
        
        # å†™å…¥äº†è§£é¢†åŸŸçš„è®ºæ–‡ï¼ˆæ‘˜è¦ç¿»è¯‘ï¼‰
        if secondary_analyses:
            f.write("# äº†è§£é¢†åŸŸè®ºæ–‡ï¼ˆæ‘˜è¦ç¿»è¯‘ï¼‰\n\n")
            for i, (paper, translation) in enumerate(secondary_analyses, 1):
                author_names = [author.name for author in paper.authors]
                
                f.write(f"## {i}. {paper.title}\n\n")
                f.write(f"**ä½œè€…**: {', '.join(author_names)}\n\n")
                f.write(f"**ç±»åˆ«**: {', '.join(paper.categories)}\n\n")
                f.write(f"**å‘å¸ƒæ—¥æœŸ**: {paper.published.strftime('%Y-%m-%d')}\n\n")
                f.write(f"**ArXiv ID**: {paper.get_short_id()}\n\n")
                f.write(f"**é“¾æ¥**: {paper.entry_id}\n\n")
                f.write(f"### æ‘˜è¦ç¿»è¯‘\n\n{translation}\n\n")
                f.write("---\n\n")
    
    logger.info(f"åˆ†æç»“æœå·²å†™å…¥ {conclusion_file.absolute()}")
    return conclusion_file

def format_email_content(priority_analyses, secondary_analyses):
    """æ ¼å¼åŒ–é‚®ä»¶å†…å®¹ï¼ŒåŒ…å«ä¸¤ç§ç±»å‹çš„è®ºæ–‡"""
    today = datetime.datetime.now().strftime('%Y-%m-%d')
    
    content = f"## ä»Šæ—¥ArXivè®ºæ–‡åˆ†ææŠ¥å‘Š ({today})\n\n"
    content += f"**é‡ç‚¹å…³æ³¨è®ºæ–‡**: {len(priority_analyses)} ç¯‡\n"
    content += f"**äº†è§£é¢†åŸŸè®ºæ–‡**: {len(secondary_analyses)} ç¯‡\n\n"
    
    # é‡ç‚¹å…³æ³¨è®ºæ–‡
    if priority_analyses:
        content += "### ğŸ”¥ é‡ç‚¹å…³æ³¨è®ºæ–‡ï¼ˆå®Œæ•´åˆ†æï¼‰\n\n"
        for i, (paper, analysis) in enumerate(priority_analyses, 1):
            author_names = [author.name for author in paper.authors]
            
            content += f"#### {i}. {paper.title}\n"
            content += f"**ä½œè€…**: {', '.join(author_names)}\n"
            content += f"**ç±»åˆ«**: {', '.join(paper.categories)}\n"
            content += f"**å‘å¸ƒæ—¥æœŸ**: {paper.published.strftime('%Y-%m-%d')}\n"
            content += f"**é“¾æ¥**: {paper.entry_id}\n\n"
            content += f"{analysis}\n\n"
            content += "---\n\n"
    
    # äº†è§£é¢†åŸŸè®ºæ–‡
    if secondary_analyses:
        content += "### ğŸ“– äº†è§£é¢†åŸŸè®ºæ–‡ï¼ˆæ‘˜è¦ç¿»è¯‘ï¼‰\n\n"
        for i, (paper, translation) in enumerate(secondary_analyses, 1):
            author_names = [author.name for author in paper.authors]
            
            content += f"#### {i}. {paper.title}\n"
            content += f"**ä½œè€…**: {', '.join(author_names)}\n"
            content += f"**ç±»åˆ«**: {', '.join(paper.categories)}\n"
            content += f"**å‘å¸ƒæ—¥æœŸ**: {paper.published.strftime('%Y-%m-%d')}\n"
            content += f"**é“¾æ¥**: {paper.entry_id}\n\n"
            content += f"{translation}\n\n"
            content += "---\n\n"
    
    return content

def delete_pdf(pdf_path):
    """åˆ é™¤PDFæ–‡ä»¶"""
    try:
        if pdf_path.exists():
            pdf_path.unlink()
            logger.info(f"å·²åˆ é™¤PDFæ–‡ä»¶: {pdf_path}")
        else:
            logger.info(f"PDFæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤: {pdf_path}")
    except Exception as e:
        logger.error(f"åˆ é™¤PDFæ–‡ä»¶å¤±è´¥ {pdf_path}: {str(e)}")

def send_email(content, attachment_path=None):
    """å‘é€é‚®ä»¶ï¼Œæ”¯æŒQQé‚®ç®±ï¼Œæ”¹è¿›é”™è¯¯å¤„ç†ï¼Œä¼˜åŒ–å­—ä½“æ ·å¼ï¼Œæ”¯æŒé™„ä»¶"""
    if not all([SMTP_SERVER, SMTP_PORT, SMTP_USERNAME, SMTP_PASSWORD, EMAIL_FROM]) or not EMAIL_TO:
        logger.error("é‚®ä»¶é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡å‘é€é‚®ä»¶")
        return

    try:
        # åˆ›å»ºé‚®ä»¶å®¹å™¨ï¼Œæ”¯æŒé™„ä»¶
        msg = MIMEMultipart('mixed')
        msg['From'] = EMAIL_FROM
        msg['To'] = ", ".join(EMAIL_TO)
        msg['Subject'] = f"{EMAIL_SUBJECT_PREFIX} - {datetime.datetime.now().strftime('%Y-%m-%d')}"

        # åˆ›å»ºé‚®ä»¶æ­£æ–‡éƒ¨åˆ†
        body_part = MIMEMultipart('alternative')
        
        # è½¬æ¢Markdownä¸ºHTMLï¼Œä½¿ç”¨æ›´å°çš„å­—ä½“
        html_content = content
        
        # è½¬æ¢æ ‡é¢˜
        html_content = html_content.replace('## ', '<h1>')
        html_content = html_content.replace('### ğŸ”¥', '<h2><span style="font-size: 16px;">ğŸ”¥</span>')
        html_content = html_content.replace('### ğŸ“–', '<h2><span style="font-size: 16px;">ğŸ“–</span>')
        html_content = html_content.replace('### ', '<h2>')
        html_content = html_content.replace('#### ', '<h3>')
        
        # å¤„ç†åŠ ç²—æ–‡æœ¬
        import re
        html_content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', html_content)
        
        # å¤„ç†é“¾æ¥ (å¦‚æœæœ‰çš„è¯)
        html_content = re.sub(r'https?://[^\s<>"]+', r'<a href="\g<0>" style="color: #3498db; text-decoration: none; word-break: break-all;">\g<0></a>', html_content)
        
        # è½¬æ¢æ¢è¡Œ
        html_content = html_content.replace('\n\n', '</p><p>')
        html_content = html_content.replace('\n', '<br>')
        
        # å¤„ç†åˆ†éš”çº¿
        html_content = html_content.replace('---', '<hr style="border: none; border-top: 1px solid #eee; margin: 15px 0;">')
        
        # åŒ…è£…æ®µè½
        html_content = f'<p>{html_content}</p>'
        
        # æ¸…ç†å¤šä½™çš„æ®µè½æ ‡ç­¾
        html_content = html_content.replace('<p></p>', '')
        html_content = html_content.replace('<p><hr', '<hr')
        html_content = html_content.replace('></p>', '>')
        html_content = html_content.replace('<p><h1>', '<h1>')
        html_content = html_content.replace('</h1></p>', '</h1>')
        html_content = html_content.replace('<p><h2>', '<h2>')
        html_content = html_content.replace('</h2></p>', '</h2>')
        html_content = html_content.replace('<p><h3>', '<h3>')
        html_content = html_content.replace('</h3></p>', '</h3>')
        
        # ä¸ºç¿»è¯‘å†…å®¹æ·»åŠ ç‰¹æ®Šæ ·å¼
        html_content = html_content.replace('**ä¸­æ–‡æ ‡é¢˜**:', '<strong style="color: #e74c3c; font-size: 14px;">ä¸­æ–‡æ ‡é¢˜</strong>:')
        html_content = html_content.replace('**æ‘˜è¦ç¿»è¯‘**:', '<strong style="color: #e74c3c; font-size: 14px;">æ‘˜è¦ç¿»è¯‘</strong>:')
        
        # åˆ›å»ºå®Œæ•´çš„HTMLæ–‡æ¡£
        final_html = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            font-size: 13px;
            line-height: 1.4;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 15px;
            background-color: #f8f9fa;
        }}
        .container {{
            background-color: white;
            padding: 20px;
            border-radius: 6px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }}
        h1 {{
            font-size: 18px;
            color: #2c3e50;
            margin: 0 0 12px 0;
            padding-bottom: 6px;
            border-bottom: 2px solid #3498db;
        }}
        h2 {{
            font-size: 16px;
            color: #34495e;
            margin: 16px 0 8px 0;
            padding-bottom: 4px;
            border-bottom: 1px solid #eee;
        }}
        h3 {{
            font-size: 14px;
            color: #2980b9;
            margin: 12px 0 6px 0;
        }}
        p {{
            margin: 6px 0;
            font-size: 13px;
        }}
        strong {{
            color: #2c3e50;
            font-weight: 600;
        }}
        a {{
            color: #3498db;
            text-decoration: none;
        }}
        a:hover {{
            text-decoration: underline;
        }}
        /* ç¿»è¯‘å†…å®¹ç‰¹æ®Šæ ·å¼ */
        .translation-content {{
            font-size: 14px;
            line-height: 1.5;
        }}
    </style>
</head>
<body>
    <div class="container">
        {html_content}
    </div>
</body>
</html>
        """
        
        # æ·»åŠ æ–‡æœ¬å’ŒHTMLç‰ˆæœ¬åˆ°æ­£æ–‡éƒ¨åˆ†
        part1 = MIMEText(content, 'plain', 'utf-8')
        part2 = MIMEText(final_html, 'html', 'utf-8')
        body_part.attach(part1)
        body_part.attach(part2)
        
        # å°†æ­£æ–‡éƒ¨åˆ†æ·»åŠ åˆ°ä¸»é‚®ä»¶
        msg.attach(body_part)
        
        # æ·»åŠ é™„ä»¶
        if attachment_path and attachment_path.exists():
            try:
                from email.mime.application import MIMEApplication
                
                with open(attachment_path, 'rb') as f:
                    attach = MIMEApplication(f.read(), _subtype='octet-stream')
                    attach.add_header('Content-Disposition', 'attachment', 
                                    filename=f'{attachment_path.name}')
                    msg.attach(attach)
                    logger.info(f"å·²æ·»åŠ é™„ä»¶: {attachment_path.name}")
            except Exception as e:
                logger.warning(f"æ·»åŠ é™„ä»¶å¤±è´¥: {str(e)}")

        # è¿æ¥åˆ°SMTPæœåŠ¡å™¨
        logger.info(f"æ­£åœ¨è¿æ¥åˆ° {SMTP_SERVER}:{SMTP_PORT}")
        
        # ä½¿ç”¨é€‚å½“çš„è¿æ¥æ–¹å¼
        if SMTP_PORT == 465:
            # ä½¿ç”¨SSLè¿æ¥
            import ssl
            context = ssl.create_default_context()
            server = smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT, context=context)
            logger.info("ä½¿ç”¨SSLè¿æ¥")
        else:
            # ä½¿ç”¨TLSè¿æ¥
            server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT, timeout=30)
            server.starttls()
            logger.info("ä½¿ç”¨TLSè¿æ¥")
        
        # ç™»å½•
        logger.info(f"æ­£åœ¨ç™»å½•é‚®ç®±: {SMTP_USERNAME}")
        server.login(SMTP_USERNAME, SMTP_PASSWORD)
        
        # å‘é€é‚®ä»¶
        logger.info(f"æ­£åœ¨å‘é€é‚®ä»¶ç»™: {EMAIL_TO}")
        text = msg.as_string()
        server.sendmail(EMAIL_FROM, EMAIL_TO, text)
        
        # å®‰å…¨å…³é—­è¿æ¥
        try:
            server.quit()
        except:
            server.close()

        attachment_info = f" (åŒ…å«é™„ä»¶: {attachment_path.name})" if attachment_path and attachment_path.exists() else ""
        logger.info(f"é‚®ä»¶å‘é€æˆåŠŸï¼Œæ”¶ä»¶äºº: {', '.join(EMAIL_TO)}{attachment_info}")
        return True
        
    except Exception as e:
        logger.error(f"å‘é€é‚®ä»¶å¤±è´¥: {str(e)}")
        # å¦‚æœæ˜¯æˆ‘ä»¬å·²çŸ¥çš„æ— å®³é”™è¯¯ï¼Œä½†é‚®ä»¶å¯èƒ½å·²ç»å‘é€
        error_str = str(e)
        if "b'\\x00\\x00\\x00\\x00'" in error_str or "(-1," in error_str:
            logger.warning("é‚®ä»¶å¯èƒ½å·²å‘é€æˆåŠŸï¼Œä½†æœåŠ¡å™¨å“åº”å¼‚å¸¸ã€‚è¯·æ£€æŸ¥æ”¶ä»¶ç®±ã€‚")
            return True
        
        # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return False

def main():
    logger.info("å¼€å§‹arXivè®ºæ–‡è·Ÿè¸ª")
    logger.info(f"é…ç½®ä¿¡æ¯:")
    logger.info(f"- æœç´¢ç±»åˆ«: {', '.join(CATEGORIES)}")
    logger.info(f"- æœ€å¤§è®ºæ–‡æ•°: {MAX_PAPERS}")
    logger.info(f"- æœç´¢å¤©æ•°: {SEARCH_DAYS}")
    logger.info(f"- é‡ç‚¹ä¸»é¢˜æ•°é‡: {len(PRIORITY_TOPICS)}")
    logger.info(f"- äº†è§£ä¸»é¢˜æ•°é‡: {len(SECONDARY_TOPICS)}")
    
    # è·å–æœ€è¿‘å‡ å¤©çš„è®ºæ–‡
    papers = get_recent_papers(CATEGORIES, MAX_PAPERS)
    logger.info(f"ä»æœ€è¿‘å‡ å¤©æ‰¾åˆ°{len(papers)}ç¯‡è®ºæ–‡")
    
    if not papers:
        logger.info("æ‰€é€‰æ—¶é—´æ®µæ²¡æœ‰æ‰¾åˆ°è®ºæ–‡ã€‚é€€å‡ºã€‚")
        return
    
    # å¤„ç†æ¯ç¯‡è®ºæ–‡
    priority_analyses = []  # é‡ç‚¹å…³æ³¨è®ºæ–‡çš„å®Œæ•´åˆ†æ
    secondary_analyses = [] # äº†è§£é¢†åŸŸè®ºæ–‡çš„æ‘˜è¦ç¿»è¯‘
    
    priority_count = 0
    secondary_count = 0
    skipped_count = 0
    
    for i, paper in enumerate(papers, 1):
        logger.info(f"æ­£åœ¨å¤„ç†è®ºæ–‡ {i}/{len(papers)}: {paper.title}")
        
        # æ£€æŸ¥ä¸»é¢˜ç›¸å…³æ€§å’Œä¼˜å…ˆçº§
        priority, reason = check_topic_relevance(paper)
        
        if priority == 1:
            # é‡ç‚¹å…³æ³¨è®ºæ–‡ï¼šä¸‹è½½PDFå¹¶è¿›è¡Œå®Œæ•´åˆ†æ
            priority_count += 1
            logger.info(f"é‡ç‚¹å…³æ³¨è®ºæ–‡ {priority_count}: {paper.title} ({reason})")
            
            pdf_path = download_paper(paper, PAPERS_DIR)
            if pdf_path:
                time.sleep(PRIORITY_ANALYSIS_DELAY)  # ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„å»¶æ—¶
                analysis = analyze_paper_with_deepseek(pdf_path, paper)
                priority_analyses.append((paper, analysis))
                delete_pdf(pdf_path)
                
        elif priority == 2:
            # äº†è§£é¢†åŸŸè®ºæ–‡ï¼šåªç¿»è¯‘æ‘˜è¦
            secondary_count += 1
            logger.info(f"äº†è§£é¢†åŸŸè®ºæ–‡ {secondary_count}: {paper.title} ({reason})")
            
            time.sleep(SECONDARY_ANALYSIS_DELAY)  # ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„å»¶æ—¶
            translation = translate_abstract_with_deepseek(paper)
            secondary_analyses.append((paper, translation))
            
        else:
            # ä¸ç›¸å…³è®ºæ–‡ï¼šè·³è¿‡
            skipped_count += 1
            logger.info(f"è·³è¿‡ä¸ç›¸å…³è®ºæ–‡: {paper.title}")
    
    logger.info(f"å¤„ç†å®Œæˆ - é‡ç‚¹å…³æ³¨: {priority_count}ç¯‡, äº†è§£é¢†åŸŸ: {secondary_count}ç¯‡, è·³è¿‡: {skipped_count}ç¯‡")
    
    if not priority_analyses and not secondary_analyses:
        logger.info("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®ºæ–‡ï¼Œä¸å‘é€é‚®ä»¶ã€‚")
        return
    
    # å°†åˆ†æç»“æœå†™å…¥å¸¦æ—¶é—´æˆ³çš„.mdæ–‡ä»¶
    result_file = write_to_conclusion(priority_analyses, secondary_analyses)
    
    # å‘é€é‚®ä»¶ï¼ŒåŒ…å«é™„ä»¶
    email_content = format_email_content(priority_analyses, secondary_analyses)
    email_success = send_email(email_content, attachment_path=result_file)
    
    if email_success:
        logger.info("é‚®ä»¶å‘é€å®Œæˆ")
    else:
        logger.warning("é‚®ä»¶å‘é€å¯èƒ½å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥")
    
    logger.info("ArXivè®ºæ–‡è¿½è¸ªå’Œåˆ†æå®Œæˆ")
    logger.info(f"ç»“æœå·²ä¿å­˜è‡³ {result_file.absolute()}")

if __name__ == "__main__":
    main()
