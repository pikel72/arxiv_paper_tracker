name: Daily Paper Analysis

on:
  schedule:
    - cron: '20 1 * * *'  # 每天北京时间早上9:20运行 (UTC 01:20)
  workflow_dispatch:  # 允许手动触发

jobs:
  analyze-papers:
    runs-on: ubuntu-latest
    timeout-minutes: 40  # 设置超时时间为40分钟
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'  # 启用pip缓存
    
    - name: Cache papers directory
      uses: actions/cache@v3
      with:
        path: papers
        key: ${{ runner.os }}-papers-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-papers-
    
    - name: Create necessary directories
      run: |
        mkdir -p papers
        mkdir -p results
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run paper analysis
      env:
        # API和邮件配置 (敏感信息)
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        GLM_API_KEY: ${{ secrets.GLM_API_KEY }}
        QWEN_API_KEY: ${{ secrets.QWEN_API_KEY }}
        # AI模型选择配置
        AI_PROVIDER: ${{ vars.AI_PROVIDER || 'qwen' }}
        AI_MODEL: ${{ vars.AI_MODEL || 'qwen-plus' }}
        # QQ邮箱服务器配置
        SMTP_SERVER: ${{ secrets.SMTP_SERVER }}
        SMTP_PORT: ${{ secrets.SMTP_PORT }}
        SMTP_USERNAME: ${{ secrets.SMTP_USERNAME }}
        SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}
        EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
        EMAIL_TO: ${{ secrets.EMAIL_TO }}
        # ArXiv搜索配置
        ARXIV_CATEGORIES: ${{ vars.ARXIV_CATEGORIES || 'math.AP' }}
        MAX_PAPERS: ${{ vars.MAX_PAPERS || '50' }}
        SEARCH_DAYS: ${{ vars.SEARCH_DAYS || '3' }}
        # 主题过滤配置
        PRIORITY_TOPICS: ${{ vars.PRIORITY_TOPICS || 'Navier-Stokes方程|Euler方程|湍流' }}
        SECONDARY_TOPICS: ${{ vars.SECONDARY_TOPICS || '色散偏微分方程|调和分析|极大算子' }}
        # API调用延时配置
        PRIORITY_ANALYSIS_DELAY: ${{ vars.PRIORITY_ANALYSIS_DELAY || '3' }}
        SECONDARY_ANALYSIS_DELAY: ${{ vars.SECONDARY_ANALYSIS_DELAY || '2' }}
        # 邮件配置
        EMAIL_SUBJECT_PREFIX: ${{ vars.EMAIL_SUBJECT_PREFIX || 'ArXiv论文分析报告' }}
      run: |
        python src/main.py
    
    - name: Upload analysis results
      uses: actions/upload-artifact@v4  # 升级到 v4
      if: always()  # 即使脚本失败也上传结果
      with:
        name: arxiv-analysis-results-${{ github.run_number }}
        path: results/
        retention-days: 30
    
    - name: Clean up temporary files
      run: |
        rm -rf papers/*.pdf

    - name: Push results to pages_src repo
      if: github.repository == 'pikel72/arxiv_paper_tracker'
      uses: actions/checkout@v3
      with:
        repository: pikel72/pages_src
        token: ${{ secrets.GH_PAGES_TOKEN }}
        path: pages_src

    - name: Copy analysis results to pages_src repo
      if: github.repository == 'pikel72/arxiv_paper_tracker'
      run: |
        mkdir -p pages_src/content/report/
        latest_file=$(ls -t results/*.md | head -n 1)
        cp "$latest_file" pages_src/content/report/

    - name: Commit and push to pages_src
      if: github.repository == 'pikel72/arxiv_paper_tracker'
      run: |
        cd pages_src
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git add content/report/
        git commit -m "Update daily arxiv analysis results [${{ github.run_number }}]" || echo "No changes to commit"
        git push

